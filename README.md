# Computer-Vision-Project-Summer-2022
**Computer Vision Lab Project - Mustafa Waked 318577921 and Layan Haddad 318369709**

**<ins>Paper:</ins>** "Deep Rectangling for Image Stitching: A Learning Baseline" (March 2022)

**<ins>Paper purpose:</ins>** the known image rectangling methods mainly work on searching an initial mesh and optimizing a target mesh to form the mesh deformation in two stages. Then rectangular images can be generated by warping stitched images. HOWEVER, these methods only work for images with rich linear structures. Which means that portrait and landscape images would most likely suffer from distortions if these methods were applied on them. THIS PAPER CAME TO PROVIDE A SOLUTION FOR THIS ISSUE.

**<ins>Paper modifications:</ins>** We were provided with 2 modifications to choose from, the first one being "Editing the training set by implementing standard geometric augmentations on the data set" and the second one was "Seam Carving" which is an algorithm for content-aware image resizing, where we had to implement the algorithm using the paper by modifying some part of the code, we decided to go with the first option.

So, why there was a need to modify the training data in the first place?

In the article, particulary on page 5 (step 4), we can see that the researchers have generated 60,000 samples, and out of this big number of samples, only 5705 were chosen for the training process, and thus eliminating approximately 95% of the samples. And so by implementing standard geometric augmentations on those data the chances of eliminating further samples shall be reduced.


**<ins>Our algorithm for modifying the data:</ins>**

Our approach for a possible geometric augmentation:

**<ins>Crop and scale:</ins>** we take a certain part of the image, perform cropping on it, and then resize this part to be the same size as the original image.

**<ins>Implementation:</ins>** The full implementation of this geometric augmentation can be found in inference2.py, whereas if one runs the file, they shall have the new data set generated AUTOMATICALLY. PLEASE consider changing the paths of the files to match your coding environment. After running the file, we saved the results in final_res.py.

The **<ins>inference2.py</ins>** path file: DeepRectangling/Codes/inference.py2 <br />
The **<ins>final_rest.py</ins>** path file: DeepRectangling/Codes/Data/DIR-D/final_res

**<ins>Training with the new generated data:</ins>**

Training can be performed exactly as described in the paper readme file. With few differences: since none of us have GPU on our laptops, we decided to use google COLAB that offeres a perfectly free training environment with a GPU. Again, please be aware of the files path before starting the training.

To make sure the model trains smoothly, please make sure to add the following code cells to your colab notebook:

cd drive/MyDrive/DeepRectangling/Codes

!pip install tensorflow==1.13.1

import tensorflow as tf
print(tf.__version__)

!pip uninstall keras
!pip install keras==2.2.3

!pip install numpy==1.18.1

import numpy
print(numpy.__version__)

!python train.py


**<ins>Testing the model trained with the new data</ins>**

After training, please follow the instructions on the readme file of the paper to preform the testing. (Be sure to change the files paths as well).


**<ins>RESULTS</ins>**

The testing results shouldn't be any different than the original paper results, as our goal was to implement standard aumgentations for generating a new data, and by using these augmentations on further samples, the amount of the eliminated samples is supposed to be better than 95%.


**Best,
Mustafa and Layan, University of Haifa, Sept 2022.**
